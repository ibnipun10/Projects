{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.io as scp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testData = scp.loadmat('../data/svhn/test_32x32.mat')\n",
    "trainData = scp.loadmat('../data/svhn/train_32x32.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testDataX = testData['X']\n",
    "testDataY = testData['y']\n",
    "\n",
    "trainDataX = trainData['X']\n",
    "trainDataY = trainData['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "(32, 32, 3, 73257)\n",
      "(73257, 1)\n",
      "(32, 32, 3, 26032)\n",
      "(26032, 1)\n"
     ]
    }
   ],
   "source": [
    "print type(trainDataX)\n",
    "print type(trainDataY)\n",
    "\n",
    "print trainDataX.shape\n",
    "print trainDataY.shape\n",
    "print testDataX.shape\n",
    "print testDataY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try tansposing the array\n",
    "def transposeArray(data):\n",
    "    print 'started'\n",
    "    xtrain = []\n",
    "    trainLen = data.shape[3]\n",
    "    print trainLen\n",
    "    for x in xrange(trainLen):\n",
    "        xtrain.append(data[:,:,:,x])\n",
    "    \n",
    "    xtrain = np.asarray(xtrain)\n",
    "    return xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "73257\n",
      "started\n",
      "26032\n",
      "(73257, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "trainDataX = transposeArray(trainDataX)\n",
    "testDataX = transposeArray(testDataX)\n",
    "\n",
    "\n",
    "print trainDataX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OnehotEndoding(Y):\n",
    "    Ytr=[]\n",
    "    for el in Y:\n",
    "        temp=np.zeros(10)\n",
    "        if el==10:\n",
    "            temp[0]=1\n",
    "        elif el==1:\n",
    "            temp[1]=1\n",
    "        elif el==2:\n",
    "            temp[2]=1\n",
    "        elif el==3:\n",
    "            temp[3]=1\n",
    "        elif el==4:\n",
    "            temp[4]=1\n",
    "        elif temp[5]==1:\n",
    "            temp[5]=1\n",
    "        elif temp[6]==1:\n",
    "            temp[6]=1\n",
    "        elif temp[7]==1:\n",
    "            temp[7]=1\n",
    "        elif temp[8]==1:\n",
    "            temp[8]=1\n",
    "        elif temp[9]==1:\n",
    "            temp[9]=1\n",
    "        Ytr.append(temp)\n",
    "        \n",
    "    return np.asarray(Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73257, 10)\n",
      "(26032, 10)\n"
     ]
    }
   ],
   "source": [
    "# convert y to one hot encoding\n",
    "trainDataY = OnehotEndoding(trainDataY)\n",
    "testDataY = OnehotEndoding(testDataY)\n",
    "print trainDataY.shape\n",
    "print testDataY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "height = 32\n",
    "width = 32\n",
    "channel = 3\n",
    "n_classes = 10\n",
    "learning_rate = 0.01\n",
    "hidden = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def WeightBias(input, output):\n",
    "    w = tf.Variable(tf.random_normal([input, output]))\n",
    "    b = tf.Variable(tf.random_normal([output]))\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73257, 3072)\n"
     ]
    }
   ],
   "source": [
    "#for fully connected we will reshape it to a flat one\n",
    "trainDataX = trainDataX.reshape((-1, height * width * channel))\n",
    "testDataX = testDataX.reshape((-1, height * width * channel))\n",
    "print trainDataX.shape\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, height * width * channel))\n",
    "y = tf.placeholder(tf.float32, shape=(None, n_classes))\n",
    "\n",
    "w1, b1 = WeightBias(height * width * channel, hidden)\n",
    "w2, b2 = WeightBias(hidden, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X, w1, b1, w2, b2):\n",
    "    h1 = tf.nn.relu(tf.matmul(X, w1) + b1)\n",
    "    return tf.matmul(h1, w2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = model(x, w1, b1, w2, b2)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred,1),tf.argmax(y,1)), \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "cost at step :  0 1.2839\n",
      "cost at step :  1 1.17909\n",
      "cost at step :  2 1.13914\n",
      "cost at step :  3 1.12046\n",
      "cost at step :  4 1.11034\n",
      "cost at step :  5 1.10432\n",
      "cost at step :  6 1.10078\n",
      "cost at step :  7 1.09836\n",
      "cost at step :  8 1.09728\n",
      "cost at step :  9 1.09657\n",
      "cost at step :  10 1.09603\n",
      "cost at step :  11 1.0955\n",
      "cost at step :  12 1.09538\n",
      "cost at step :  13 1.09533\n",
      "cost at step :  14 1.0952\n",
      "cost at step :  15 1.09514\n",
      "cost at step :  16 1.09501\n",
      "cost at step :  17 1.095\n",
      "cost at step :  18 1.095\n",
      "cost at step :  19 1.09491\n",
      "cost at step :  20 1.09495\n",
      "cost at step :  21 1.09481\n",
      "cost at step :  22 1.09504\n",
      "cost at step :  23 1.09508\n",
      "cost at step :  24 1.0951\n",
      "cost at step :  25 1.09499\n",
      "cost at step :  26 1.09503\n",
      "cost at step :  27 1.09485\n",
      "cost at step :  28 1.09486\n",
      "cost at step :  29 1.09496\n",
      "cost at step :  30 1.09494\n",
      "cost at step :  31 1.09506\n",
      "cost at step :  32 1.09503\n",
      "cost at step :  33 1.09499\n",
      "cost at step :  34 1.09494\n",
      "cost at step :  35 1.09479\n",
      "cost at step :  36 1.09503\n",
      "cost at step :  37 1.0951\n",
      "cost at step :  38 1.09498\n",
      "cost at step :  39 1.0951\n",
      "cost at step :  40 1.09494\n",
      "cost at step :  41 1.09508\n",
      "cost at step :  42 1.0952\n",
      "cost at step :  43 1.09507\n",
      "cost at step :  44 1.09515\n",
      "cost at step :  45 1.09511\n",
      "cost at step :  46 1.09512\n",
      "cost at step :  47 1.09513\n",
      "cost at step :  48 1.09504\n",
      "cost at step :  49 1.09499\n",
      "accuracy on training data 0.189224\n",
      "Accuracy on test data: 0.195913\n"
     ]
    }
   ],
   "source": [
    "num_steps = 50\n",
    "batch = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print('Initialized')\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        p = np.random.permutation(range(len(trainDataX)))\n",
    "        trX, trY = trainDataX[p], trainDataY[p]\n",
    "        \n",
    "        for start in range(0, len(trainDataX), batch):\n",
    "            end = start + batch\n",
    "            sess.run(optimizer, feed_dict={x:trX[start:end], y:trY[start:end]})\n",
    "        \n",
    "        print 'cost at step : ', step, sess.run(loss, feed_dict={x:trX, y:trY})\n",
    "\n",
    "    \n",
    "    # calculate the accuracy on the training data\n",
    "    print 'accuracy on training data', sess.run(accuracy, feed_dict={x:trainDataX, y:trainDataY})\n",
    "    \n",
    "    print \"Accuracy on test data:\", accuracy.eval({x: testDataX, y: testDataY})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
