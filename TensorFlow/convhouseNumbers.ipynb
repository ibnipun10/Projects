{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.io as scp\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testData = scp.loadmat('../data/svhn/test_32x32.mat')\n",
    "trainData = scp.loadmat('../data/svhn/train_32x32.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testDataX = testData['X']\n",
    "testDataY = testData['y']\n",
    "\n",
    "trainDataX = trainData['X']\n",
    "trainDataY = trainData['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "(32, 32, 3, 73257)\n",
      "(73257, 1)\n",
      "(32, 32, 3, 26032)\n",
      "(26032, 1)\n"
     ]
    }
   ],
   "source": [
    "print type(trainDataX)\n",
    "print type(trainDataY)\n",
    "\n",
    "print trainDataX.shape\n",
    "print trainDataY.shape\n",
    "print testDataX.shape\n",
    "print testDataY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try tansposing the array\n",
    "def transposeArray(data):\n",
    "    print 'started'\n",
    "    xtrain = []\n",
    "    trainLen = data.shape[3]\n",
    "    print trainLen\n",
    "    for x in xrange(trainLen):\n",
    "        xtrain.append(data[:,:,:,x])\n",
    "    \n",
    "    xtrain = np.asarray(xtrain)\n",
    "    return xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "73257\n",
      "started\n",
      "26032\n",
      "(73257, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "trainDataX = transposeArray(trainDataX)\n",
    "testDataX = transposeArray(testDataX)\n",
    "\n",
    "\n",
    "print trainDataX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OnehotEndoding(Y):\n",
    "    Ytr=[]\n",
    "    for el in Y:\n",
    "        temp=np.zeros(10)\n",
    "        if el==10:\n",
    "            temp[0]=1\n",
    "        elif el==1:\n",
    "            temp[1]=1\n",
    "        elif el==2:\n",
    "            temp[2]=1\n",
    "        elif el==3:\n",
    "            temp[3]=1\n",
    "        elif el==4:\n",
    "            temp[4]=1\n",
    "        elif temp[5]==1:\n",
    "            temp[5]=1\n",
    "        elif temp[6]==1:\n",
    "            temp[6]=1\n",
    "        elif temp[7]==1:\n",
    "            temp[7]=1\n",
    "        elif temp[8]==1:\n",
    "            temp[8]=1\n",
    "        elif temp[9]==1:\n",
    "            temp[9]=1\n",
    "        Ytr.append(temp)\n",
    "        \n",
    "    return np.asarray(Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73257, 10)\n",
      "(26032, 10)\n"
     ]
    }
   ],
   "source": [
    "# convert y to one hot encoding\n",
    "trainDataY = OnehotEndoding(trainDataY)\n",
    "testDataY = OnehotEndoding(testDataY)\n",
    "print trainDataY.shape\n",
    "print testDataY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height = 32\n",
    "width = 32\n",
    "channel = 3\n",
    "tags = 10\n",
    "patch = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "learning_rate = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_X = tf.placeholder(\"float\", shape=[None, height, width, channel])\n",
    "tf_Y = tf.placeholder(\"float\", shape=[None, tags])\n",
    "\n",
    "convW1 = tf.Variable(tf.random_normal([patch, patch, channel, depth], stddev=0.1))\n",
    "bias1 = tf.Variable(tf.random_normal([depth], stddev=0.1))\n",
    "\n",
    "convW2 = tf.Variable(tf.random_normal([patch, patch, depth, depth], stddev=0.1))\n",
    "bias2 = tf.Variable(tf.random_normal([depth], stddev=0.1))\n",
    "\n",
    "w3 = tf.Variable(tf.random_normal([height // 4 * width // 4 * depth, num_hidden], stddev=0.1))\n",
    "bias3 = tf.Variable(tf.random_normal([num_hidden]))\n",
    "\n",
    "w4 = tf.Variable(tf.random_normal([num_hidden, tags], stddev=0.1))\n",
    "bias4 = tf.Variable(tf.random_normal([tags], stddev=0.1))              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model\n",
    "def model(X):\n",
    "    conv = tf.nn.conv2d(X, convW1, [1,2,2,1], padding='SAME')\n",
    "    hidden1 = tf.nn.relu(conv + bias1)\n",
    "    \n",
    "    conv2 = tf.nn.conv2d(hidden1, convW2, [1,2,2,1], padding='SAME')\n",
    "    hidden2 = tf.nn.relu(conv2 + bias2)\n",
    "    \n",
    "    #reshape it to a single Dimensional\n",
    "    shape = hidden2.get_shape()\n",
    "    print hidden2.get_shape().as_list()\n",
    "    \n",
    "    newInput = tf.reshape(hidden2, [-1, shape[1].value * shape[2].value * shape[3].value])\n",
    "    hidden3 = tf.nn.relu(tf.matmul(newInput, w3) + bias3)\n",
    "    \n",
    "    return tf.matmul(hidden3, w4) + bias4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 8, 8, 16]\n"
     ]
    }
   ],
   "source": [
    "pred = model(tf_X)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, tf_Y))\n",
    "\n",
    "# Optimizer.\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred,1),tf.argmax(tf_Y,1)), \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Accuracy(X, Y, message, sess):    \n",
    "    print message, sess.run(accuracy, feed_dict= {tf_X: X, tf_Y: Y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Initialized\n",
      "cost at each step : 0 is : 245.22\n",
      "cost at each step : 50 is : 19.9122\n",
      "cost at each step : 100 is : 19.2203\n",
      "cost at each step : 150 is : 22.6261\n",
      "cost at each step : 200 is : 101.576\n",
      "cost at each step : 250 is : 6278.88\n",
      "cost at each step : 300 is : 29.0328\n",
      "cost at each step : 350 is : 12.0666\n",
      "cost at each step : 400 is : 5.65341\n",
      "cost at each step : 450 is : 3.81649\n",
      "cost at each step : 500 is : 3.66395\n",
      "cost at each step : 550 is : 2.66991\n",
      "cost at each step : 600 is : 3.32461\n",
      "cost at each step : 650 is : 2.14366\n",
      "cost at each step : 700 is : 1.96371\n",
      "cost at each step : 750 is : 1.76727\n",
      "cost at each step : 800 is : 2.39551\n",
      "cost at each step : 850 is : 1.67991\n",
      "cost at each step : 900 is : 2.11456\n",
      "cost at each step : 950 is : 1.72611\n",
      "cost at each step : 1000 is : 1.99279\n",
      "cost at each step : 1050 is : 1.92433\n",
      "cost at each step : 1100 is : 1.52921\n",
      "cost at each step : 1150 is : 1.6069\n",
      "cost at each step : 1200 is : 1.69033\n",
      "cost at each step : 1250 is : 1.68714\n",
      "cost at each step : 1300 is : 1.42673\n",
      "cost at each step : 1350 is : 1.88231\n",
      "cost at each step : 1400 is : 1.45986\n",
      "cost at each step : 1450 is : 1.8328\n",
      "cost at each step : 1500 is : 1.97526\n",
      "cost at each step : 1550 is : 1.57901\n",
      "cost at each step : 1600 is : 1.45113\n",
      "cost at each step : 1650 is : 1.69645\n",
      "cost at each step : 1700 is : 1.35402\n",
      "cost at each step : 1750 is : 2.10231\n",
      "cost at each step : 1800 is : 1.77596\n",
      "cost at each step : 1850 is : 1.71655\n",
      "cost at each step : 1900 is : 1.57591\n",
      "cost at each step : 1950 is : 1.54868\n",
      "cost at each step : 2000 is : 1.7496\n",
      "cost at each step : 2050 is : 1.49566\n",
      "cost at each step : 2100 is : 1.45176\n",
      "cost at each step : 2150 is : 2.4136\n",
      "cost at each step : 2200 is : 1.52365\n",
      "cost at each step : 2250 is : 1.54696\n",
      "cost at each step : 2300 is : 1.43883\n",
      "cost at each step : 2350 is : 1.84193\n",
      "cost at each step : 2400 is : 1.6606\n",
      "cost at each step : 2450 is : 1.78356\n",
      "cost at each step : 2500 is : 1.64965\n",
      "cost at each step : 2550 is : 1.45113\n",
      "cost at each step : 2600 is : 1.78866\n",
      "cost at each step : 2650 is : 1.965\n",
      "cost at each step : 2700 is : 1.83353\n",
      "cost at each step : 2750 is : 1.35324\n",
      "cost at each step : 2800 is : 1.38905\n",
      "cost at each step : 2850 is : 1.90557\n",
      "cost at each step : 2900 is : 1.61714\n",
      "cost at each step : 2950 is : 1.4222\n",
      "cost at each step : 3000 is : 1.73076\n",
      "cost at each step : 3050 is : 1.32809\n",
      "cost at each step : 3100 is : 1.3564\n",
      "cost at each step : 3150 is : 1.39647\n",
      "cost at each step : 3200 is : 1.53684\n",
      "cost at each step : 3250 is : 1.55348\n",
      "cost at each step : 3300 is : 1.64364\n",
      "cost at each step : 3350 is : 1.62095\n",
      "cost at each step : 3400 is : 1.70295\n",
      "cost at each step : 3450 is : 1.60262\n",
      "cost at each step : 3500 is : 1.44117\n",
      "cost at each step : 3550 is : 1.36011\n",
      "cost at each step : 3600 is : 1.31689\n",
      "cost at each step : 3650 is : 1.38241\n",
      "cost at each step : 3700 is : 1.46546\n",
      "cost at each step : 3750 is : 1.50163\n",
      "cost at each step : 3800 is : 1.71822\n",
      "cost at each step : 3850 is : 1.39606\n",
      "cost at each step : 3900 is : 1.45064\n",
      "cost at each step : 3950 is : 1.78913\n",
      "cost at each step : 4000 is : 1.6457\n",
      "cost at each step : 4050 is : 1.32023\n",
      "cost at each step : 4100 is : 1.32755\n",
      "cost at each step : 4150 is : 1.47734\n",
      "cost at each step : 4200 is : 1.42122\n",
      "cost at each step : 4250 is : 1.53445\n",
      "cost at each step : 4300 is : 1.3228\n",
      "cost at each step : 4350 is : 1.4298\n",
      "cost at each step : 4400 is : 1.75555\n",
      "cost at each step : 4450 is : 1.27769\n",
      "cost at each step : 4500 is : 1.33863\n",
      "cost at each step : 4550 is : 1.61559\n",
      "cost at each step : 4600 is : 1.57711\n",
      "cost at each step : 4650 is : 1.51099\n",
      "cost at each step : 4700 is : 1.31621\n",
      "cost at each step : 4750 is : 1.5456\n",
      "cost at each step : 4800 is : 1.48382\n",
      "cost at each step : 4850 is : 1.15389\n",
      "cost at each step : 4900 is : 1.49983\n",
      "cost at each step : 4950 is : 1.46786\n",
      "cost at each step : 5000 is : 1.46446\n",
      "cost at each step : 5050 is : 1.48343\n",
      "cost at each step : 5100 is : 1.52595\n",
      "cost at each step : 5150 is : 1.29712\n",
      "cost at each step : 5200 is : 1.43854\n",
      "cost at each step : 5250 is : 1.33704\n",
      "cost at each step : 5300 is : 1.51241\n",
      "cost at each step : 5350 is : 1.67567\n",
      "cost at each step : 5400 is : 1.5436\n",
      "cost at each step : 5450 is : 1.53217\n",
      "cost at each step : 5500 is : 1.5245\n",
      "cost at each step : 5550 is : 1.69168\n",
      "cost at each step : 5600 is : 1.26889\n",
      "cost at each step : 5650 is : 1.78852\n",
      "cost at each step : 5700 is : 1.30317\n",
      "cost at each step : 5750 is : 1.22812\n",
      "cost at each step : 5800 is : 1.78458\n",
      "cost at each step : 5850 is : 1.36418\n",
      "cost at each step : 5900 is : 1.57785\n",
      "cost at each step : 5950 is : 1.89239\n",
      "cost at each step : 6000 is : 1.32618\n",
      "cost at each step : 6050 is : 1.44319\n",
      "cost at each step : 6100 is : 1.46928\n",
      "cost at each step : 6150 is : 1.3466\n",
      "cost at each step : 6200 is : 1.23545\n",
      "cost at each step : 6250 is : 1.60157\n",
      "cost at each step : 6300 is : 1.55949\n",
      "cost at each step : 6350 is : 1.96479\n",
      "cost at each step : 6400 is : 1.33681\n",
      "cost at each step : 6450 is : 1.6254\n",
      "cost at each step : 6500 is : 1.73587\n",
      "cost at each step : 6550 is : 1.58334\n",
      "cost at each step : 6600 is : 1.87153\n",
      "cost at each step : 6650 is : 1.30167\n",
      "cost at each step : 6700 is : 1.81226\n",
      "cost at each step : 6750 is : 1.60376\n",
      "cost at each step : 6800 is : 1.07216\n",
      "cost at each step : 6850 is : 1.57458\n",
      "cost at each step : 6900 is : 1.58\n",
      "cost at each step : 6950 is : 1.64071\n",
      "cost at each step : 7000 is : 1.85266\n",
      "cost at each step : 7050 is : 1.5704\n",
      "cost at each step : 7100 is : 1.40078\n",
      "cost at each step : 7150 is : 2.0394\n",
      "cost at each step : 7200 is : 1.52697\n",
      "cost at each step : 7250 is : 2.10188\n",
      "cost at each step : 7300 is : 1.97912\n",
      "cost at each step : 7350 is : 1.58395\n",
      "cost at each step : 7400 is : 1.49305\n",
      "cost at each step : 7450 is : 1.45781\n",
      "cost at each step : 7500 is : 1.85536\n",
      "cost at each step : 7550 is : 1.24186\n",
      "cost at each step : 7600 is : 1.63312\n",
      "cost at each step : 7650 is : 1.90366\n",
      "cost at each step : 7700 is : 1.74917\n",
      "cost at each step : 7750 is : 1.43634\n",
      "cost at each step : 7800 is : 2.04191\n",
      "cost at each step : 7850 is : 1.69763\n",
      "cost at each step : 7900 is : 1.89385\n",
      "cost at each step : 7950 is : 1.94863\n",
      "cost at each step : 8000 is : 1.81431\n",
      "cost at each step : 8050 is : 2.67874\n",
      "cost at each step : 8100 is : 1.94959\n",
      "cost at each step : 8150 is : 1.56078\n",
      "cost at each step : 8200 is : 1.53798\n",
      "cost at each step : 8250 is : 2.13876\n",
      "cost at each step : 8300 is : 2.1989\n",
      "cost at each step : 8350 is : 2.26464\n",
      "cost at each step : 8400 is : 2.13413\n",
      "cost at each step : 8450 is : 2.74939\n",
      "cost at each step : 8500 is : 2.13941\n",
      "cost at each step : 8550 is : 2.5861\n",
      "cost at each step : 8600 is : 1.94671\n",
      "cost at each step : 8650 is : 3.72707\n",
      "cost at each step : 8700 is : 3.17914\n",
      "cost at each step : 8750 is : 2.83223\n",
      "cost at each step : 8800 is : 2.86737\n",
      "cost at each step : 8850 is : 2.3917\n",
      "cost at each step : 8900 is : 3.30578\n",
      "cost at each step : 8950 is : 3.1497\n",
      "cost at each step : 9000 is : 4.26693\n",
      "cost at each step : 9050 is : 3.80283\n",
      "cost at each step : 9100 is : 3.22352\n",
      "cost at each step : 9150 is : 4.17533\n",
      "cost at each step : 9200 is : 5.39301\n",
      "cost at each step : 9250 is : 6.97073\n",
      "cost at each step : 9300 is : 9.52113\n",
      "cost at each step : 9350 is : 9.56603\n",
      "cost at each step : 9400 is : 11.1533\n",
      "cost at each step : 9450 is : 23.2797\n",
      "cost at each step : 9500 is : 248.454\n",
      "cost at each step : 9550 is : 1992.6\n",
      "cost at each step : 9600 is : 73.1856\n",
      "cost at each step : 9650 is : 68.0739\n",
      "cost at each step : 9700 is : 104.393\n",
      "cost at each step : 9750 is : 3736.9\n",
      "cost at each step : 9800 is : 24.4869\n",
      "cost at each step : 9850 is : 7.96077\n",
      "cost at each step : 9900 is : 7.72424\n",
      "cost at each step : 9950 is : 7.34218\n",
      "accuracy of training data :  0.448503\n",
      "accuracy of test data :  0.437116\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    epoch = 10000\n",
    "    batch_size = 100\n",
    "    print('Initialized')\n",
    "    \n",
    "    p = np.random.permutation(range(len(trainDataX)))\n",
    "    trX, trY = trainDataX[p], trainDataY[p]\n",
    "    \n",
    "    for step in range(epoch):\n",
    "        \n",
    "        batch = np.random.choice(len(trainDataX) - 1, batch_size)\n",
    "        inX, outY = trainDataX[batch], trainDataY[batch]\n",
    "        sess.run(optimizer, feed_dict= {tf_X: inX, tf_Y: outY})\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            print 'cost at each step :', step, 'is :', sess.run(loss, feed_dict={tf_X: inX, tf_Y: outY})\n",
    "    \n",
    "    Accuracy(trainDataX, trainDataY, 'accuracy of training data : ', sess)\n",
    "    Accuracy(testDataX, testDataY, 'accuracy of test data : ', sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
